{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdfdXc01XNX5"
      },
      "source": [
        "\n",
        "# Efficient-spiking-networks/ECG/adapt_srnn_0.844_gpu-v1.py\n",
        "## From public github repo byin-cwi /\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Up9ImQ0XzhJ"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuqA444V81aI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "this code works,\n",
        "1. 36 recurrent neurons will lead to 84.4 percent on testset\n",
        "2. 24 recurrent neurons will lead to 81.8 percent on testset\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR,MultiStepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.utils import shuffle\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import scipy.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCJVwuSiX6xi"
      },
      "source": [
        "#### Initializing some physiological and technical model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jNE1nAyYJOr",
        "outputId": "b4bca5f2-72a8-4c24-f479-2e997b23d93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device:  cpu\n",
            "surrograte_type:  MG\n",
            "neuron_type:  adaptive\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device =  torch.device(\"cpu\")\n",
        "print('device: ',device)\n",
        "\n",
        "'''\n",
        "STEP 3a_v2: CREATE Adaptative spike MODEL CLASS\n",
        "'''\n",
        "b_j0 = 0.01  # neural threshold baseline\n",
        "tau_m = 20  # ms membrane potential constant\n",
        "R_m = 1  # membrane resistance\n",
        "dt = 1  #\n",
        "gamma = .5  # gradient scale #TM: Learning rate ?\n",
        "lens = 0.5\n",
        "\n",
        "surrograte_type = 'MG'\n",
        "print('surrograte_type: ',surrograte_type)\n",
        "\n",
        "neuron_type = 'adaptive'\n",
        "print('neuron_type: ',neuron_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thifYfL0YMSa"
      },
      "source": [
        "#### Standard Gaussian distribution used for the new gradiant method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS6zi7xqYoNl"
      },
      "outputs": [],
      "source": [
        "def gaussian(x, mu=0., sigma=.5):\n",
        "    return torch.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / torch.sqrt(2 * torch.tensor(math.pi)) / sigma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW-o7n9JYp47"
      },
      "source": [
        "#### From autograd baseclass for individual gradient implementation. If surrogate set to 'MG', backward propagation is implemented using the multi-gaussian as defined in the paper with three normal distributions centered on the neuron's membrane potential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVQwRCcMaB5F"
      },
      "outputs": [],
      "source": [
        "# define approximate firing function\n",
        "\n",
        "class ActFun_adp(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):  # input = membrane potential- threshold\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.gt(0).float()  # is firing ???\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):  # approximate the gradients\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        # temp = abs(input) < lens\n",
        "        scale = 6.0\n",
        "        hight = .15\n",
        "        if surrograte_type == 'G':\n",
        "            temp = torch.exp(-(input**2)/(2*lens**2))/torch.sqrt(2*torch.tensor(math.pi))/lens\n",
        "        elif surrograte_type == 'MG':\n",
        "            temp = gaussian(input, mu=0., sigma=lens) * (1. + hight) \\\n",
        "                - gaussian(input, mu=lens, sigma=scale * lens) * hight \\\n",
        "                - gaussian(input, mu=-lens, sigma=scale * lens) * hight\n",
        "        elif surrograte_type =='linear':\n",
        "            temp = F.relu(1-input.abs())\n",
        "        elif surrograte_type == 'slayer':\n",
        "            temp = torch.exp(-5*input.abs())\n",
        "        return grad_input * temp.float() * gamma\n",
        "# membrane potential update\n",
        "\n",
        "act_fun_adp = ActFun_adp.apply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M_yEESUahy3"
      },
      "source": [
        "#### Deciding between ALIF and LIF neural models, the membrane update step is defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG1QkQq8af7Z"
      },
      "outputs": [],
      "source": [
        "if neuron_type =='adaptive':\n",
        "    def mem_update_adp(inputs, mem, spike, tau_m,tau_adp, b, isAdapt=1, dt=1):\n",
        "        alpha = torch.exp(-1. * dt / tau_m)#.cuda()\n",
        "        ro = torch.exp(-1. * dt / tau_adp)#.cuda()\n",
        "        # tau_adp is tau_adaptative which is learnable # add requiregredients\n",
        "        if isAdapt:\n",
        "            beta = 1.8\n",
        "        else:\n",
        "            beta = 0.\n",
        "\n",
        "        b = ro * b + (1 - ro) * spike\n",
        "        B = b_j0 + beta * b\n",
        "\n",
        "        mem = mem * alpha + (1 - alpha) * R_m * inputs - B * spike * dt\n",
        "        inputs_ = mem - B\n",
        "        spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
        "        return mem, spike, B, b\n",
        "\n",
        "if neuron_type  == 'LIF':\n",
        "    def mem_update_adp(inputs, mem, spike, tau_m, tau_adp, b, dt=1, isAdapt=1):\n",
        "\n",
        "        b = 0\n",
        "        B = .5\n",
        "        alpha = torch.exp(-1. * dt / tau_adp)#.cuda()\n",
        "        mem = mem *.618 + inputs#*(1- alpha)\n",
        "        inputs_ = mem - B\n",
        "        spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
        "        mem = (1-spike)*mem \n",
        "        return mem, spike, B, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0yzyTrKfW6a"
      },
      "source": [
        "#### SRNN model with individualized forward feeding and prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfIy9PfTfUdB"
      },
      "outputs": [],
      "source": [
        "class RNN_s(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, sub_seq_length,criterion):\n",
        "        super(RNN_s, self).__init__()\n",
        "        self.criterion = criterion\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.sub_seq_length = sub_seq_length\n",
        "        self.i2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.tau_adp_h = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.tau_adp_o = nn.Parameter(torch.Tensor(output_size))\n",
        "        \n",
        "        self.tau_m_h = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.tau_m_o = nn.Parameter(torch.Tensor(output_size))\n",
        "        \n",
        "        nn.init.orthogonal_(self.h2h.weight)\n",
        "        nn.init.xavier_uniform_(self.i2h.weight)\n",
        "        nn.init.xavier_uniform_(self.h2o.weight)\n",
        "        nn.init.constant_(self.i2h.bias, 0)\n",
        "        nn.init.constant_(self.h2h.bias, 0)\n",
        "        nn.init.constant_(self.h2o.bias, 0)\n",
        "\n",
        "        nn.init.constant_(self.tau_adp_h, 7) #7\n",
        "        nn.init.constant_(self.tau_adp_o, 100)\n",
        "        nn.init.constant_(self.tau_m_h, 20) #7\n",
        "        nn.init.constant_(self.tau_m_o, 20)\n",
        "        \n",
        "        self.b_h = self.b_o = 0\n",
        "\n",
        "    def forward(self, input,labels):\n",
        "        self.b_h = self.b_o = b_j0\n",
        "        total_spikes = 0\n",
        "        # Feed in the whole sequence\n",
        "        batch_size, seq_num, input_dim = input.shape\n",
        "        hidden_mem = hidden_spike = (torch.rand(batch_size, self.hidden_size)*b_j0)#TM:.cuda()\n",
        "        output_mem = output_spike = out_spike = (torch.rand(batch_size, self.output_size)*b_j0)#TM:.cuda()\n",
        "        output_spike_sum = torch.zeros(batch_size,seq_num, self.output_size)#TM:.cuda()\n",
        "        self.b_h = self.b_o = 0.01\n",
        "\n",
        "        max_iters = 1301\n",
        "        loss = 0\n",
        "\n",
        "        output_ = []\n",
        "        I_h = []\n",
        "        predictions = []\n",
        "        for i in range(max_iters): # Go through the sequence\n",
        "            if i < seq_num:\n",
        "                input_x = input[:, i, :]\n",
        "            else:\n",
        "                input_x = torch.zeros(batch_size,input_dim)\n",
        "\n",
        "            #################   update states  #########################\n",
        "            h_input = self.i2h(input_x.float()) + self.h2h(hidden_spike)\n",
        "            hidden_mem, hidden_spike, theta_h, self.b_h = mem_update_adp(h_input,hidden_mem, hidden_spike,self.tau_m_h,\n",
        "                                                                            self.tau_adp_h, self.b_h,isAdapt=0)#0\n",
        "\n",
        "            I_h.append(h_input.data.cpu().numpy())\n",
        "            o_input = self.h2o(hidden_spike)\n",
        "            output_mem, output_spike, theta_o, self.b_o = mem_update_adp(o_input,output_mem,output_spike,self.tau_m_o, \n",
        "                                                                         self.tau_adp_o, self.b_o,isAdapt=1)#, dt=input_dt_o)\n",
        "            output_spike_sum[:,i,:] = output_spike\n",
        "            total_spikes = total_spikes + int(hidden_spike.sum() + output_spike.sum())\n",
        "            #################   classification  #########################\n",
        "            if i >= self.sub_seq_length:\n",
        "                output_sumspike = output_mem #output_spike_sum[:, i-1:i, :].sum(axis=1)\n",
        "                output_sumspike = F.log_softmax(output_sumspike,dim=1)\n",
        "\n",
        "                predictions.append(output_sumspike.data.cpu().numpy())\n",
        "                output_.append(output_sumspike.data.cpu().numpy())\n",
        "                loss += self.criterion(output_sumspike, labels[:, i])\n",
        "\n",
        "        predictions = torch.tensor(predictions)\n",
        "        return predictions, loss , total_spikes\n",
        "\n",
        "    def predict(self,input, lablel):\n",
        "        prediction = self.forward(input, lablel)\n",
        "        # prediction, _, total_spikes = self.forward(dt_h, dt_o, max_i, input, lablel)\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COkUSDs8hGmv"
      },
      "source": [
        "#### Train model in-place by reference, return training accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXXS0LYfg1H3"
      },
      "outputs": [],
      "source": [
        "def train(model,dims, loader,optimizer,scheduler=None,num_epochs=10):\n",
        "    best_acc = 0\n",
        "    path = 'model/'  # .pth'\n",
        "    acc_list=[]\n",
        "    for epoch in range(num_epochs):\n",
        "        train_acc = 0\n",
        "        train_loss_sum = 0\n",
        "        sum_samples = 0\n",
        "        for i, (images, labels) in enumerate(loader):\n",
        "            images = images.view(-1, dims[\"samples\"], dims[\"input\"]).requires_grad_().to(device)#images.view(-1, num_samples, input_dim).requires_grad_().to(device)\n",
        "            labels = labels.view((-1,dims[\"samples\"])).long().to(device)\n",
        "\n",
        "            # Clear gradients w.r.t. parameters\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass to get output/logits\n",
        "            predictions, train_loss,_ = model(images, labels)\n",
        "\n",
        "            _, predicted = torch.max(predictions.data, 2)\n",
        "            \n",
        "            # Getting gradients w.r.t. parameters\n",
        "            train_loss.backward()\n",
        "            train_loss_sum += train_loss\n",
        "            optimizer.step()\n",
        "\n",
        "            labels = labels.cpu()\n",
        "            #print(predicted.type(), labels.type())\n",
        "            predicted = predicted.cpu().t()\n",
        "            train_acc += (predicted == labels[:, dims[\"sub_seq\"]:predicted.shape[1] + dims[\"sub_seq\"]]).sum()\n",
        "            sum_samples = sum_samples + predicted.numel()\n",
        "            # train_acc += (predicted == labels).sum()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        train_acc = train_acc.data.cpu().numpy() / sum_samples\n",
        "        if train_acc>best_acc and train_acc>0.80:\n",
        "            best_acc = train_acc\n",
        "            torch.save(model.state_dict(), path+str(best_acc)[:5]+'-wt-new.pth')\n",
        "\n",
        "        acc_list.append(train_acc)\n",
        "        print('epoch: {:3d}, Train Loss: {:.4f}, Train Acc: {:.4f}'.format(epoch,\n",
        "                                                                           train_loss_sum.item()/len(loader)/(1300-dims[\"sub_seq\"]),\n",
        "                                                                           train_acc), flush=True)\n",
        "    return acc_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svVa2SFqhCFg"
      },
      "source": [
        "#### Some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Loas0hXohita"
      },
      "outputs": [],
      "source": [
        "import scipy.signal as ssg\n",
        "def convert_seq(x,threshold=0.03):\n",
        "    l = len(x)\n",
        "    x= ssg.savgol_filter(x, 5, 3)\n",
        "    X = np.zeros((l,2))\n",
        "    for i in range(len(x)-1):\n",
        "        if x[i+1] - x[i] >= threshold:\n",
        "            X[i,0] = 1\n",
        "        elif x[i] - x[i+1] >= threshold:\n",
        "            X[i,1] = 1\n",
        "    return X\n",
        "\n",
        "\n",
        "def expand_dim(x, N):\n",
        "    y = np.zeros((x.shape[0], x.shape[1], N))\n",
        "    for i in range(x.shape[0]):\n",
        "        y[i, :, :] = np.tile(x[i,:], (N,1)).transpose()\n",
        "\n",
        "    return y\n",
        "\n",
        "def lbl_to_spike(prediction):\n",
        "    N = len(prediction)\n",
        "    detections = np.zeros(N)\n",
        "    for i in range(1, N):\n",
        "        if (prediction[i] != prediction[i-1]):\n",
        "            detections[i] = prediction[i]+1\n",
        "    return detections\n",
        "\n",
        "\n",
        "def calculate_stats(prediction, lbl, tol):\n",
        "    decisions = lbl_to_spike(prediction)\n",
        "    labs = lbl_to_spike(lbl)\n",
        "\n",
        "    lbl_indices = np.nonzero(labs)\n",
        "    lbl_indices = np.array(lbl_indices).flatten()\n",
        "\n",
        "    dist = np.zeros((len(lbl_indices), 6))\n",
        "    for i in range(len(lbl_indices)):\n",
        "        index = lbl_indices[i]\n",
        "        lab = int(labs[index])\n",
        "        dec_indices = np.array(np.nonzero((decisions-lab) == 0)).flatten()  #indices where decisions == lab\n",
        "        if len(dec_indices) == 0:\n",
        "            dist[i, lab - 1] = 250\n",
        "            continue\n",
        "        j = np.argmin(np.abs(dec_indices - index))  # j is closest val in dec_indices to index\n",
        "        dist[i, lab-1] = abs(dec_indices[j]-index)\n",
        "        if (dist[i, lab-1] <= tol):\n",
        "            decisions[dec_indices[j]] = 0 # mark as handled\n",
        "\n",
        "    mean_error = np.mean(dist, axis=0)\n",
        "    TP = np.sum(dist <= tol, axis=0)\n",
        "    FN = np.sum(dist > tol, axis=0)\n",
        "\n",
        "    FP = np.zeros(6)\n",
        "    for i in decisions[(decisions > 0)]:\n",
        "        FP[int(i-1)] += 1\n",
        "\n",
        "    return mean_error, TP, FN, FP\n",
        "\n",
        "def convert_dataset_wtime(mat_data):\n",
        "    X = mat_data[\"x\"]\n",
        "    Y = mat_data[\"y\"]\n",
        "    t = mat_data[\"t\"]\n",
        "    Y = np.argmax(Y[:, :, :], axis=-1)\n",
        "    d1,d2 =  t.shape\n",
        "\n",
        "    # dt = np.zeros((size(t[:, 1]), size(t[1, :])))\n",
        "    dt = np.zeros((d1,d2))\n",
        "    for trace in range(d1):\n",
        "        dt[trace, 0] = 1\n",
        "        dt[trace, 1:] = t[trace, 1:] - t[trace, :-1]\n",
        "\n",
        "    return dt, X, Y\n",
        "\n",
        "\n",
        "def load_max_i(mat_data):\n",
        "    max_i = mat_data[\"max_i\"]\n",
        "    return np.array(max_i.squeeze(),dtype=np.float16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg53y-damPUt"
      },
      "source": [
        "#### Step by Step execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIpQVzOymIHw"
      },
      "outputs": [],
      "source": [
        "train_mat = scipy.io.loadmat('SRNN_Datasets/QTDB_train.mat')\n",
        "test_mat = scipy.io.loadmat('SRNN_Datasets/QTDB_test.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agaAjImjmTY3",
        "outputId": "899df3f1-7eeb-49f6-ea62-0848e6613b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequence length: 1301 , input dimension: 4\n",
            "training dataset distribution:  (618, 1301)\n",
            "test dataset distribution:  (141, 1301)\n"
          ]
        }
      ],
      "source": [
        "train_dt, train_x, train_y = convert_dataset_wtime(train_mat)\n",
        "train_max_i = load_max_i(train_mat)\n",
        "test_dt, test_x, test_y = convert_dataset_wtime(test_mat)\n",
        "test_max_i = load_max_i(test_mat)\n",
        "nb_of_sample, seq_dim, input_dim = np.shape(train_x)\n",
        "print('sequence length: {} , input dimension: {}'.format(seq_dim, input_dim))\n",
        "print('training dataset distribution: ',train_y.shape)\n",
        "print('test dataset distribution: ',test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5dJzCM-maGD"
      },
      "outputs": [],
      "source": [
        "# STEP 2: MAKING DATASET ITERABLE\n",
        "batch_size = 64\n",
        "n_iters = 300\n",
        "lens = 0.5  # hyper-parameters of approximate function\n",
        "#num_epochs = 1#250  # n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = 0#400 #400\n",
        "#nb_of_batch = nb_of_sample // batch_size\n",
        "\n",
        "sub_seq_length = 10\n",
        "#L = seq_dim - sub_seq_length\n",
        "hidden_dim = 36\n",
        "if neuron_type =='LIF': hidden_dim = 36\n",
        "output_dim = 6\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x*1.),torch.from_numpy(train_y))\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=False)\n",
        "test_data = TensorDataset(torch.from_numpy(test_x*1.),torch.from_numpy(test_y))\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=False)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "model = RNN_s(input_size=input_dim, hidden_size=hidden_dim,\n",
        "              output_size=output_dim, sub_seq_length=sub_seq_length,criterion=criterion)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "learning_rate =1e-2\n",
        "\n",
        "base_params = [model.i2h.weight, model.i2h.bias, model.h2h.weight,\n",
        "                model.h2h.bias, model.h2o.weight, model.h2o.bias]\n",
        "\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': base_params},\n",
        "    {'params': model.tau_m_h, 'lr': learning_rate * 3},\n",
        "    {'params': model.tau_m_o, 'lr': learning_rate * 2},\n",
        "    {'params': model.tau_adp_h, 'lr': learning_rate * 3},\n",
        "    {'params': model.tau_adp_o, 'lr': learning_rate * 2}, ],\n",
        "    lr=learning_rate)\n",
        "# scheduler = StepLR(optimizer, step_size=100, gamma=.75) # gaussian\n",
        "scheduler = StepLR(optimizer, step_size=100, gamma=.5) # LIF\n",
        "\n",
        "# training network\n",
        "dims = {\n",
        "    \"samples\": seq_dim,\n",
        "    \"input\": input_dim,\n",
        "    \"hidden\": hidden_dim,\n",
        "    \"output\": output_dim,\n",
        "    \"sub_seq\": sub_seq_length\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdLV32YUnqzU"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88w5bRsDo6ja",
        "outputId": "2355ef86-5146-4991-bc6f-e10a3e52558e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNN_s(\n",
              "  (criterion): NLLLoss()\n",
              "  (i2h): Linear(in_features=4, out_features=36, bias=True)\n",
              "  (h2h): Linear(in_features=36, out_features=36, bias=True)\n",
              "  (h2o): Linear(in_features=36, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7TL3BEmnJCp",
        "outputId": "671e1170-1c5d-4766-ef05-d7752c1f1fe8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:   0, Train Loss: 1.6057, Train Acc: 0.3132\n",
            "epoch:   1, Train Loss: 1.5205, Train Acc: 0.3199\n",
            "epoch:   2, Train Loss: 1.4820, Train Acc: 0.3338\n",
            "epoch:   3, Train Loss: 1.4299, Train Acc: 0.3532\n",
            "epoch:   4, Train Loss: 1.3747, Train Acc: 0.4362\n"
          ]
        }
      ],
      "source": [
        "train_acc_list = train(model,dims, train_loader,optimizer,scheduler,num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6VGTY1_nLw1",
        "outputId": "727ca0d0-5a48-4e16-fbd2-c5bda9dae847"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNN_s(\n",
              "  (criterion): NLLLoss()\n",
              "  (i2h): Linear(in_features=4, out_features=36, bias=True)\n",
              "  (h2h): Linear(in_features=36, out_features=36, bias=True)\n",
              "  (h2o): Linear(in_features=36, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "0cPVG822tsoA",
        "outputId": "4b206435-3757-465d-8325-20c02af13cc7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_seq_dim = test_x.shape[1]\n",
        "\n",
        "tau_adp_o = model.tau_adp_o.detach().cpu().numpy()\n",
        "plt.plot(tau_adp_o)\n",
        "plt.show()\n",
        "tau_adp_h = model.tau_adp_h.detach().cpu().numpy()\n",
        "plt.plot(tau_adp_h)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy75_QtQt2WL",
        "outputId": "7e7b7871-06a0-478b-ad85-7399986161ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.576297443841983\n",
            "10 0.5620026758678967\n",
            "20 0.5219283685588876\n",
            "30 0.5194023137852628\n",
            "40 0.5286505072641741\n",
            "50 0.5245363831047524\n",
            "60 0.49990476311411913\n",
            "70 0.510315183120411\n",
            "80 0.5006646202101921\n",
            "90 0.5058179620534384\n",
            "100 0.5133943293632229\n",
            "110 0.5162141227207068\n",
            "120 0.5131200747706628\n",
            "130 0.5117046375080565\n",
            "140 0.5084848185199224\n",
            "fr: 0.3775625535237618\n",
            "test accuracy:  0.5084848185199224\n",
            "[[ 7253     0     0     0  2446 32100]\n",
            " [ 1760     0     0     2   180  8203]\n",
            " [  384     0     0    20   344  9092]\n",
            " [   54     0     0    18  2388  6605]\n",
            " [  496     0     0     2 38565 16822]\n",
            " [ 5643     0     0     0  2930 46724]]\n",
            "classification report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.17      0.25     41799\n",
            "           1       0.00      0.00      0.00     10145\n",
            "           2       0.00      0.00      0.00      9840\n",
            "           3       0.43      0.00      0.00      9065\n",
            "           4       0.82      0.69      0.75     55885\n",
            "           5       0.39      0.84      0.53     55297\n",
            "\n",
            "    accuracy                           0.51    182031\n",
            "   macro avg       0.35      0.29      0.26    182031\n",
            "weighted avg       0.50      0.51      0.45    182031\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "acc = []\n",
        "predicted_list = []\n",
        "labels_list = []\n",
        "fr_list = []\n",
        "stats = {\"err\": 0, \"TP\": 0, \"FP\": 0, \"FN\": 0}\n",
        "for i in range(len(test_x)):\n",
        "    x_emp = test_x[i:i+1]\n",
        "    y_emp = test_y[i:i+1]\n",
        "\n",
        "    images = torch.tensor(x_emp*1.).view((-1, test_seq_dim, input_dim)).requires_grad_().to(device)\n",
        "    labels = torch.tensor(y_emp).view((-1, test_seq_dim)).long().to(device)\n",
        "\n",
        "    pred,_,spike=  model.forward(images,labels) #model.predict(images,labels)\n",
        "    # print(pred.shape, pred.dtype)\n",
        "    # print(pred.numpy().shape )\n",
        "    a_len = 1301-sub_seq_length\n",
        "    a_np = pred.data.cpu().numpy().reshape(a_len, 6)\n",
        "    a_np_pred = np.argmax(a_np, axis=1)\n",
        "    labels = y_emp[0, sub_seq_length:sub_seq_length+a_len].reshape(a_len)\n",
        "    acc_ = (a_np_pred == labels).sum() / int(a_len)\n",
        "    acc.append(acc_)\n",
        "    labels_list.extend(labels)\n",
        "    predicted_list.extend(a_np_pred)\n",
        "    fr_list.append(spike)\n",
        "    if i%10 == 0:\n",
        "        print(i,np.mean(acc))\n",
        "\n",
        "    err, TP, FN, FP = calculate_stats(a_np_pred[30:-30], labels[30:-30], 0.150 * 250)\n",
        "    stats[\"err\"] = stats[\"err\"] + err / len(test_x)\n",
        "    stats[\"TP\"] = stats[\"TP\"] + TP\n",
        "    stats[\"FP\"] = stats[\"FP\"] + FP\n",
        "    stats[\"FN\"] = stats[\"FN\"] + FN\n",
        "\n",
        "print('fr:',np.mean(fr_list)/1301./42.)\n",
        "test_acc = np.mean(acc)\n",
        "print('test accuracy: ',np.mean(acc))\n",
        "\n",
        "predicted_list = np.array(predicted_list).reshape((-1,))\n",
        "labels_list = np.array(labels_list).reshape(((-1,)))\n",
        "cm = confusion_matrix(labels_list, predicted_list)\n",
        "print(cm)\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"classification report :\", metrics.classification_report(labels_list, predicted_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dBxc0hAjjN2"
      },
      "source": [
        "### Execution of .py call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7S9GbMl8AA9"
      },
      "outputs": [],
      "source": [
        "#if __name__ == '__main__':\n",
        "# STEP 2: LOADING DATASET\n",
        "train_mat = scipy.io.loadmat('SRNN_Datasets/QTDB_train.mat')\n",
        "test_mat = scipy.io.loadmat('SRNN_Datasets/QTDB_test.mat')\n",
        "\n",
        "# # old dataset\n",
        "# xxt = np.load('dataset/test_y.npy')\n",
        "# print(xxt.shape)\n",
        "# xxt = np.load('dataset/xxt.npy')\n",
        "# yyt = np.load('dataset/yyt.npy')\n",
        "# xxv = np.load('dataset/xxv.npy')\n",
        "# yyv = np.load('dataset/yyv.npy')\n",
        "\n",
        "train_dt, train_x, train_y = convert_dataset_wtime(train_mat)\n",
        "train_max_i = load_max_i(train_mat)\n",
        "test_dt, test_x, test_y = convert_dataset_wtime(test_mat)\n",
        "test_max_i = load_max_i(test_mat)\n",
        "\n",
        "nb_of_sample, seq_dim, input_dim = np.shape(train_x)\n",
        "print('sequence length: {} , input dimension: {}'.format(seq_dim, input_dim))\n",
        "print('training dataset distribution: ',train_y.shape)\n",
        "print('test dataset distribution: ',test_y.shape)\n",
        "\n",
        "# STEP 2: MAKING DATASET ITERABLE\n",
        "batch_size = 64\n",
        "n_iters = 300000\n",
        "lens = 0.5  # hyper-parameters of approximate function\n",
        "#num_epochs = 1#250  # n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = 0#400 #400\n",
        "#nb_of_batch = nb_of_sample // batch_size\n",
        "\n",
        "sub_seq_length = 10\n",
        "#L = seq_dim - sub_seq_length\n",
        "hidden_dim = 36\n",
        "if neuron_type =='LIF': hidden_dim = 36\n",
        "output_dim = 6\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x*1.),torch.from_numpy(train_y))\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=False)\n",
        "test_data = TensorDataset(torch.from_numpy(test_x*1.),torch.from_numpy(test_y))\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=False)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "model = RNN_s(input_size=input_dim, hidden_size=hidden_dim,\n",
        "              output_size=output_dim, sub_seq_length=sub_seq_length,criterion=criterion)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "learning_rate =1e-2\n",
        "\n",
        "base_params = [model.i2h.weight, model.i2h.bias, model.h2h.weight,\n",
        "                model.h2h.bias, model.h2o.weight, model.h2o.bias]\n",
        "\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': base_params},\n",
        "    {'params': model.tau_m_h, 'lr': learning_rate * 3},\n",
        "    {'params': model.tau_m_o, 'lr': learning_rate * 2},\n",
        "    {'params': model.tau_adp_h, 'lr': learning_rate * 3},\n",
        "    {'params': model.tau_adp_o, 'lr': learning_rate * 2}, ],\n",
        "    lr=learning_rate)\n",
        "# scheduler = StepLR(optimizer, step_size=100, gamma=.75) # gaussian\n",
        "scheduler = StepLR(optimizer, step_size=100, gamma=.5) # LIF\n",
        "\n",
        "# training network\n",
        "dims = {\n",
        "    \"samples\": seq_dim,\n",
        "    \"input\": input_dim,\n",
        "    \"hidden\": hidden_dim,\n",
        "    \"output\": output_dim,\n",
        "    \"sub_seq\": sub_seq_length\n",
        "}\n",
        "# with sechdual\n",
        "train_acc_list = train(model,dims, train_loader,optimizer,scheduler,num_epochs=num_epochs)\n",
        "# without sechdual\n",
        "\n",
        "# train_acc_list = train(model, dims, train_loader, optimizer, num_epochs=num_epochs) # gaussian\n",
        "# test and visualization\n",
        "test_seq_dim = test_x.shape[1]\n",
        "\n",
        "tau_adp_o = model.tau_adp_o.detach().cpu().numpy()\n",
        "plt.plot(tau_adp_o)\n",
        "plt.show()\n",
        "tau_adp_h = model.tau_adp_h.detach().cpu().numpy()\n",
        "plt.plot(tau_adp_h)\n",
        "plt.show()\n",
        "\n",
        "acc = []\n",
        "predicted_list = []\n",
        "labels_list = []\n",
        "fr_list = []\n",
        "stats = {\"err\": 0, \"TP\": 0, \"FP\": 0, \"FN\": 0}\n",
        "for i in range(len(test_x)):\n",
        "    x_emp = test_x[i:i+1]\n",
        "    y_emp = test_y[i:i+1]\n",
        "\n",
        "    images = torch.tensor(x_emp*1.).view((-1, test_seq_dim, input_dim)).requires_grad_().to(device)\n",
        "    labels = torch.tensor(y_emp).view((-1, test_seq_dim)).long().to(device)\n",
        "\n",
        "    pred,_,spike=  model.forward(images,labels) #model.predict(images,labels)\n",
        "    # print(pred.shape, pred.dtype)\n",
        "    # print(pred.numpy().shape )\n",
        "    a_len = 1301-sub_seq_length\n",
        "    a_np = pred.data.cpu().numpy().reshape(a_len, 6)\n",
        "    a_np_pred = np.argmax(a_np, axis=1)\n",
        "    labels = y_emp[0, sub_seq_length:sub_seq_length+a_len].reshape(a_len)\n",
        "    acc_ = (a_np_pred == labels).sum() / int(a_len)\n",
        "    acc.append(acc_)\n",
        "    labels_list.extend(labels)\n",
        "    predicted_list.extend(a_np_pred)\n",
        "    fr_list.append(spike)\n",
        "    if i%10 == 0:\n",
        "        print(i,np.mean(acc))\n",
        "\n",
        "    err, TP, FN, FP = calculate_stats(a_np_pred[30:-30], labels[30:-30], 0.150 * 250)\n",
        "    stats[\"err\"] = stats[\"err\"] + err / len(test_x)\n",
        "    stats[\"TP\"] = stats[\"TP\"] + TP\n",
        "    stats[\"FP\"] = stats[\"FP\"] + FP\n",
        "    stats[\"FN\"] = stats[\"FN\"] + FN\n",
        "\n",
        "print('fr:',np.mean(fr_list)/1301./42.)\n",
        "test_acc = np.mean(acc)\n",
        "print('test accuracy: ',np.mean(acc))\n",
        "\n",
        "predicted_list = np.array(predicted_list).reshape((-1,))\n",
        "labels_list = np.array(labels_list).reshape(((-1,)))\n",
        "cm = confusion_matrix(labels_list, predicted_list)\n",
        "print(cm)\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"classification report :\", metrics.classification_report(labels_list, predicted_list))\n",
        "path = './model_'+str(test_acc)+'_'+str(hidden_dim)+'_MG.pth'\n",
        "torch.save(model.state_dict(), path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
