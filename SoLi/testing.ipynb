{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import h5py\n",
    "import json\n",
    "import random\n",
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from array import *\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:  (5600, 40, 32, 32) (5600,)\n",
      "dataset shape:  (2893, 40, 32, 32) (2893,)\n",
      "dataset shape:  (2849, 40, 32, 32) (2849,)\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "def dataset_cutoff(dataset_dr,target_length=40):\n",
    "    new_dataset = []\n",
    "    new_dataset_y = []\n",
    "    data_files = os.listdir(dataset_dr)\n",
    "    for f in data_files:\n",
    "        if f[0] == '.':\n",
    "                continue\n",
    "        \n",
    "        data_ = np.load(dataset_dr+f)\n",
    "        l = data_.shape[0]\n",
    "        label = int(f.split('.')[0].split('_')[0])\n",
    "        data_x = range(l)\n",
    "        if l<target_length:\n",
    "            N = int(target_length//l)+1\n",
    "            data_idx = np.tile(data_x,N)[:target_length]\n",
    "            new_dataset.append(data_[data_idx,:])\n",
    "            new_dataset_y.append(label)\n",
    "        else: \n",
    "            N = int(l//target_length)+1\n",
    "            for i in range(N): \n",
    "                if i==N-1: \n",
    "                    data_idx = data_x[-target_length:]\n",
    "                    new_dataset.append(data_[data_idx,:])\n",
    "                    new_dataset_y.append(label)\n",
    "                else: \n",
    "                    data_idx = data_x[i*target_length:(i+1)*target_length]\n",
    "                    new_dataset.append(data_[data_idx,:])\n",
    "                    new_dataset_y.append(label)\n",
    "                    \n",
    "    print('dataset shape: ',np.array(new_dataset).shape,np.array(new_dataset_y).shape)\n",
    "    return np.array(new_dataset),np.array(new_dataset_y)\n",
    "    \n",
    "new_test_dataset_x,new_test_dataset_y = dataset_cutoff('./data/npy_data/test/')\n",
    "\n",
    "new_train_dataset_x,new_train_dataset_y = dataset_cutoff('./data/npy_data/train/')\n",
    "\n",
    "new_eval_dataset_x,new_eval_dataset_y = dataset_cutoff('./data/npy_data/eval/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/data_set/test_x2.npy', new_test_dataset_x[:2893])\n",
    "# np.save('./data_set/test_x2.npy', new_test_dataset_x[2800:])\n",
    "np.save('./data/data_set/test_y2.npy', new_test_dataset_y[:2893])\n",
    "# np.save('./data_set/test_y2.npy', new_test_dataset_y[2800:])\n",
    "\n",
    "# np.save('./data/data_set/train_x.npy', new_train_dataset_x)\n",
    "# np.save('./data/data_set/train_y.npy', new_train_dataset_y)\n",
    "\n",
    "# np.save('./data/data_set/valid_x.npy', new_eval_dataset_x)\n",
    "# np.save('./data/data_set/valid_y.npy', new_eval_dataset_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy.random as random\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "batch_size =32\n",
    "train_x = np.load('./data/data_set/train_x.npy')/255.\n",
    "train_y = np.load('./data/data_set/train_y.npy')\n",
    "# plt.hist(train_y)\n",
    "\n",
    "valid_x = np.load('./data/data_set/valid_x.npy')/255.\n",
    "valid_y = np.load('./data/data_set/valid_y.npy')\n",
    "\n",
    "test_x = np.load('./data/data_set/test_x.npy')/255.\n",
    "test_y = np.load('./data/data_set/test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dataset shap:  (2893, 40, 32, 32)\n",
      "output dataset shap:  (2893,)\n"
     ]
    }
   ],
   "source": [
    "idx_not_11 = np.where(test_y < 11)[0]\n",
    "test_x = test_x[idx_not_11, :, :, :]\n",
    "test_y = test_y[idx_not_11]\n",
    "\n",
    "_, seq_length, dim_row, dim_col = train_x.shape\n",
    "print('input dataset shap: ', train_x.shape)\n",
    "print('output dataset shap: ', train_y.shape)\n",
    "\n",
    "\n",
    "def get_DataLoader(train_x, train_y, batch_size=200, is_binary=False):\n",
    "    train_y = np.tile(train_y, seq_length).reshape(seq_length, len(train_y)).T\n",
    "    if is_binary:\n",
    "        train_dataset = data.TensorDataset(\n",
    "            torch.Tensor(\n",
    "                (train_x > 0) * 1.),\n",
    "            torch.Tensor(train_y))\n",
    "    else:\n",
    "        train_dataset = data.TensorDataset(\n",
    "            torch.Tensor(train_x), torch.Tensor(train_y))\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "train_loader = get_DataLoader(train_x, train_y, batch_size=batch_size)\n",
    "test_loader = get_DataLoader(test_x, test_y, batch_size=batch_size)\n",
    "valid_loader = get_DataLoader(valid_x, valid_y, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu=0., sigma=.5):\n",
    "    return torch.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / torch.sqrt(2 * torch.tensor(math.pi)) / sigma\n",
    "\n",
    "class ActFun_adp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):  # input = membrane potential- threshold\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(0).float()  # is firing ???\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # approximate the gradients\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        # temp = abs(input) < lens\n",
    "        scale = 6.0\n",
    "        hight = .15\n",
    "        # temp = torch.exp(-(input**2)/(2*lens**2))/torch.sqrt(2*torch.tensor(math.pi))/lens\n",
    "        temp = gaussian(input, mu=0., sigma=lens) * (1. + hight) \\\n",
    "               - gaussian(input, mu=lens, sigma=scale * lens) * hight \\\n",
    "               - gaussian(input, mu=-lens, sigma=scale * lens) * hight\n",
    "        return grad_input * temp.float() * gamma\n",
    "\n",
    "act_fun_adp = ActFun_adp.apply\n",
    "\n",
    "def mem_update_adp(inputs, mem, spike, tau_adp, b, tau_m, dt=1, isAdapt=1, isExcitatory = True):\n",
    "\n",
    "    isCuda = torch.cuda.is_available()\n",
    "    if isCuda:\n",
    "        alpha = torch.exp(-1. * dt / tau_m).cuda()\n",
    "        ro = torch.exp(-1. * dt / tau_adp).cuda()\n",
    "    else:\n",
    "        alpha = torch.exp(-1. * dt / tau_m)\n",
    "        ro = torch.exp(-1. * dt / tau_adp)\n",
    "    if isAdapt:\n",
    "        beta = 1.84\n",
    "    else:\n",
    "        beta = 0.\n",
    "\n",
    "    b = ro * b + (1 - ro) * spike\n",
    "    B = b_j0 + beta * b\n",
    "\n",
    "    mem = mem * alpha + (1 - alpha) * R_m * inputs - B * spike * dt\n",
    "    inputs_ = mem - B\n",
    "    spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n",
    "    return mem, spike, B, b\n",
    "\n",
    "def output_Neuron(inputs, mem, tau_m, dt=1):\n",
    "    \"\"\"\n",
    "    The read out neuron is leaky integrator without spike\n",
    "    \"\"\"\n",
    "    alpha = torch.exp(-1. * dt / tau_m)\n",
    "    mem = mem *alpha +  (1-alpha)*inputs\n",
    "    return mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- randomly chose approximately 20% of the neurons to be turned into inhibitory neurons ---\n",
    "random.seed(1)\n",
    "inhib_neurons_indxs = set([int(random.rand(1)*256) for _ in range(256//5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_s(nn.Module):\n",
    "    def __init__(self, sub_seq_length,criterion):\n",
    "        super(RNN_s, self).__init__()\n",
    "        # --- loss ---\n",
    "        self.criterion = criterion\n",
    "        # --- wait this number of frames before classifying ---\n",
    "        self.sub_seq_length = sub_seq_length\n",
    "        \n",
    "        self.n = 256\n",
    "        self.dense_i = nn.Linear(1024,self.n)\n",
    "        self.dense_i2r = nn.Linear(self.n,self.n)\n",
    "        self.dense_r = nn.Linear(self.n,self.n)\n",
    "        self.dense_o = nn.Linear(self.n,11)\n",
    "        \n",
    "        self.tau_adp_i = nn.Parameter(torch.Tensor(self.n))\n",
    "        self.tau_adp_r = nn.Parameter(torch.Tensor(self.n))\n",
    "        self.tau_adp_o = nn.Parameter(torch.Tensor(11))\n",
    "        \n",
    "        self.tau_m_i = nn.Parameter(torch.Tensor(self.n))\n",
    "        self.tau_m_r = nn.Parameter(torch.Tensor(self.n))\n",
    "        self.tau_m_o = nn.Parameter(torch.Tensor(11))\n",
    "        \n",
    "        nn.init.normal_(self.tau_adp_i,20,5)\n",
    "        nn.init.normal_(self.tau_adp_r,20,5)\n",
    "        nn.init.normal_(self.tau_adp_o,20,5)\n",
    "        \n",
    "        nn.init.normal_(self.tau_m_i,20,5)\n",
    "        nn.init.normal_(self.tau_m_r,20,5)\n",
    "        nn.init.normal_(self.tau_m_o,3,1)\n",
    "        \n",
    "        self.b_h = self.b_o = b_j0\n",
    "\n",
    "    def forward(self, input, labels=None, sub_length=5, output_type='integrator'):\n",
    "        b,s,l = input.shape\n",
    "        # --- initilizing layers ---\n",
    "        if torch.cuda.is_available():\n",
    "            mem_layer1 = spike_layer1 = mem_layer2 = spike_layer2\\\n",
    "                 = torch.rand(b, self.n).cuda()\n",
    "            mem_layer3 = spike_layer3 = mem_output \\\n",
    "                = torch.rand(b, 11).cuda()\n",
    "            self.b_i = self.b_o = self.b_r = b_j0\n",
    "            output = torch.zeros(b, 11).cuda()\n",
    "        else:\n",
    "            mem_layer1 = spike_layer1 = mem_layer2 = spike_layer2 \\\n",
    "                = torch.rand(b, self.n)\n",
    "            mem_layer3 = spike_layer3 = mem_output = torch.rand(b, 11)\n",
    "            self.b_i = self.b_o = self.b_r = b_j0\n",
    "            output = torch.zeros(b, 11)\n",
    "        loss = 0\n",
    "        predictions = []\n",
    "        fr = []\n",
    "        # --- loop for each frame ---\n",
    "        for i in range(s):\n",
    "            input_x = input[:, i, :]\n",
    "            d1_output = self.dense_i(input_x)\n",
    "            mem_layer1, spike_layer1, theta_i, self.b_i = mem_update_adp(\n",
    "                d1_output, mem_layer1, spike_layer1, self.tau_adp_i, self.b_i, self.tau_m_i)\n",
    "\n",
    "            # --- recurent layer ---\n",
    "            r_input = self.dense_i2r(spike_layer1) + self.dense_r(spike_layer2)\n",
    "            mem_layer2, spike_layer2, theta_r, self.b_r =\\\n",
    "                mem_update_adp(r_input, mem_layer2, spike_layer2, \n",
    "                                self.tau_adp_r, self.b_r, self.tau_m_r)\n",
    "\n",
    "            # --- turn spikes from inhibitory neurons to negative spikes --- \n",
    "            #for ind in inhib_neurons_indxs:\n",
    "            #    spike_layer2[:,ind] = -1 * spike_layer2[:,ind]\n",
    "                # ---\n",
    "                \n",
    "            o_input = self.dense_o(spike_layer2)\n",
    "            if output_type == 'adp-mem':\n",
    "                mem_layer3, spike_layer3, theta_o, self.b_o = mem_update_adp(\n",
    "                    o_input, mem_layer3, spike_layer3, self.tau_adp_o, self.b_o, self.tau_m_o)\n",
    "            elif output_type == 'integrator':\n",
    "                mem_layer3 = output_Neuron(o_input, mem_layer3, self.tau_m_o)\n",
    "\n",
    "            output = F.log_softmax(mem_layer3, dim=-1)\n",
    "            # output_ = F.log_softmax(output,dim=1)\n",
    "\n",
    "            predictions.append(output.data.cpu().numpy())\n",
    "            if labels is not None:\n",
    "                loss += self.criterion(output, labels[:, i])\n",
    "\n",
    "            fr.append((spike_layer1.detach().mean().cpu().numpy() +\n",
    "                       spike_layer2.detach().mean().cpu().numpy()) / 2.)\n",
    "\n",
    "        predictions = torch.tensor(predictions)\n",
    "        return predictions, loss, np.mean(fr)\n",
    "\n",
    "    def predict(self, input):\n",
    "        prediction, _ = self.forward(input)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightConstraint(object):\n",
    "    def __init__(self, inhibitory : bool):\n",
    "        self.inhibitory = inhibitory\n",
    "    \n",
    "    def __call__(self,module):\n",
    "        if hasattr(module,'weight'):\n",
    "            print(\"clamping\")\n",
    "            w = module.weight.data\n",
    "            if not self.inhibitory:\n",
    "                w = w.clamp(0, None)\n",
    "            else:\n",
    "                w = w.clamp(None, 0)\n",
    "            module.weight.data = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wInhibit = WeightConstraint(inhibitory = True)\n",
    "wExcitat = WeightConstraint(inhibitory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_loader, after_num_frames=0):\n",
    "    test_acc = 0.\n",
    "    sum_samples = 0\n",
    "    fr_list = []\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images = images.view(-1, seq_length, 1024).to(device)\n",
    "        labels = labels.view((-1, seq_length)).long().to(device)\n",
    "        predictions, _, fr = model(images)\n",
    "        _, predicted = torch.max(predictions.data, 2)\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu().t()\n",
    "        fr_list.append(fr)\n",
    "\n",
    "        test_acc += (predicted[:, after_num_frames:] ==\n",
    "                     labels[:, after_num_frames:]).sum()\n",
    "\n",
    "        sum_samples = sum_samples + predicted.numel()\n",
    "    print('Mean FR: ', np.mean(fr_list))\n",
    "    return test_acc.data.cpu().numpy() / sum_samples\n",
    "\n",
    "\n",
    "def test_frame(data_loader, after_num_frames=0):\n",
    "    test_acc = 0.\n",
    "    sum_samples = 0\n",
    "    test_acc_classes = np.zeros((11, 40))\n",
    "    test_acc_count = np.zeros((11, 1))\n",
    "    fr_list = []\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images = images.view(-1, seq_length, 1024).to(device)\n",
    "        labels = labels.view((-1, seq_length)).long().to(device)\n",
    "        predictions, _, fr = model(images)\n",
    "        _, predicted = torch.max(predictions.data, 2)\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu().t()\n",
    "        fr_list.append(fr)\n",
    "\n",
    "        test_acc += (predicted[:, after_num_frames:] ==\n",
    "                     labels[:, after_num_frames:]).float().mean(axis=0)\n",
    "        f_test = predicted[:,\n",
    "                           after_num_frames:] == labels[:,\n",
    "                                                        after_num_frames:]\n",
    "        for i in range(f_test.shape[0]):\n",
    "            tmp = labels[i, 0]\n",
    "            test_acc_classes[tmp] += f_test[i].float().cpu().numpy()\n",
    "            test_acc_count[tmp] += 1\n",
    "        if i == 1:\n",
    "            print(f_test.shape)\n",
    "\n",
    "        sum_samples = sum_samples + predicted.numel()\n",
    "    print('Mean FR: ', np.mean(fr_list))\n",
    "\n",
    "    return test_acc.data.cpu().numpy() / i, test_acc_classes / test_acc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, scheduler=None, num_epochs=10, fracInhibitory = 0):\n",
    "    best_acc = 0\n",
    "    path = 'model/'  # .pth'\n",
    "    acc_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_acc = 0\n",
    "        train_loss_sum = 0\n",
    "        sum_samples = 0\n",
    "        fr_list = []\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            # images.view(-1, num_samples, input_dim).requires_grad_().to(device)\n",
    "            images = images.view(-1, seq_length,\n",
    "                                1024).requires_grad_().to(device)\n",
    "            labels = labels.view((-1, seq_length)).long().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # --- calls model.forward via special method ---\n",
    "            predictions, train_loss, fr_ = model(images, labels)\n",
    "            _, predicted = torch.max(predictions.data, 2)\n",
    "\n",
    "            train_loss.backward(retain_graph=True)\n",
    "            train_loss_sum += train_loss\n",
    "            fr_list.append(fr_)\n",
    "            optimizer.step()\n",
    "            nI = int(model.n * fracInhibitory)\n",
    "            # --- Enforce restrictions on weights of the recursive layer by \n",
    "            #       clamping the weights immediately after the optimizer step. ---\n",
    "            inhibitory = (slice(0, nI), slice(None)) # shape (51, 256) --> weights from first 51 neurons\n",
    "            excitatory = (slice(nI, model.n), slice(None)) # shape (205, 256) --> weights from rest\n",
    "            weights = model._modules['dense_r'].weight.data\n",
    "\n",
    "                # --- --- apply clamp to [-oo, 0] and [0, oo] --- ---\n",
    "            inh = weights[inhibitory].clamp(None, 0)\n",
    "            exc = weights[excitatory].clamp(0, None)\n",
    "            newWeights = torch.cat((inh, exc))\n",
    "\n",
    "            model._modules['dense_r'].weight.data = newWeights\n",
    "            # ---\n",
    "\n",
    "            labels = labels.cpu()\n",
    "            predicted = predicted.cpu().t()\n",
    "            train_acc += (predicted == labels).sum()\n",
    "            sum_samples = sum_samples + predicted.numel()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_acc = train_acc.data.cpu().numpy() / sum_samples\n",
    "        valid_acc = test(valid_loader)\n",
    "\n",
    "        if valid_acc > best_acc and train_acc > 0.80:\n",
    "            best_acc = valid_acc\n",
    "            torch.save(model, path + str(best_acc)[:5] + '-frame-v3-inte.pth')\n",
    "\n",
    "        acc_list.append(train_acc)\n",
    "        print(\n",
    "                'epoch: {:3d}, Train Loss: {:.4f}, Train Acc: {:.4f},Valid Acc: {:.4f},fr: {:.4f}'.format(\n",
    "                epoch, train_loss_sum.item() / len(loader) / (seq_length),\n",
    "                train_acc, valid_acc, np.mean(fr_list)),flush=True\n",
    "            )\n",
    "        \n",
    "    return acc_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(40)\n",
    "thresh = 0.5  # neuronal threshold\n",
    "b_j0 = 0.1  # neural threshold baseline\n",
    "R_m = 1  # membrane resistance\n",
    "lens = 0.5\n",
    "gamma = 0.5\n",
    "fInhibs = np.linspace(0,1,5)\n",
    "metaparameters = {'test_accuracies':[[i, 0] for i in fInhibs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobiasmoxter/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FR:  0.05936060587565105\n",
      "epoch:   0, Train Loss: 1.8578, Train Acc: 0.3135,Valid Acc: 0.5140,fr: 0.0444\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-09d4ca2c6b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         fracInhibitory=frac)\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmetaparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_accuracies'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-2497c9193944>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, scheduler, num_epochs, fracInhibitory)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# --- calls model.forward via special method ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-457ac8f4ccef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, labels, sub_length, output_type)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mmem_layer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspike_layer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_r\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 mem_update_adp(r_input, mem_layer2, spike_layer2, \n\u001b[0;32m---> 63\u001b[0;31m                                 self.tau_adp_r, self.b_r, self.tau_m_r)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# --- turn spikes from inhibitory neurons to negative spikes ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-35a0a584b391>\u001b[0m in \u001b[0;36mmem_update_adp\u001b[0;34m(inputs, mem, spike, tau_adp, b, tau_m, dt, isAdapt, isExcitatory)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_j0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mR_m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mspike\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0minputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mspike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_fun_adp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# act_fun : approximation firing function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 12\n",
    "sub_seq_length = 10\n",
    "criterion = nn.NLLLoss()  # nn.CrossEntropyLoss()\n",
    "for ind, frac in enumerate(fInhibs):\n",
    "    model = RNN_s(sub_seq_length=sub_seq_length, criterion=criterion)\n",
    "    # model.load('./model/796-mem.pth')\n",
    "    # model.load_state_dict(torch.load('./model/0.766-frame.pth'))\n",
    "    # model = torch.load('./model/0.833-frame-v3-inte.pth')\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "    model.to(device)\n",
    "\n",
    "    learning_rate = 1.5e-2  # 1e-2\n",
    "\n",
    "    base_params = [model.dense_i.weight, model.dense_i.bias,\n",
    "                model.dense_o.weight, model.dense_o.bias,\n",
    "                model.dense_r.weight, model.dense_r.bias,\n",
    "                model.dense_i2r.weight, model.dense_i2r.bias]\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': base_params},\n",
    "        {'params': model.tau_adp_i, 'lr': learning_rate * 5},\n",
    "        {'params': model.tau_adp_r, 'lr': learning_rate * 5},\n",
    "        {'params': model.tau_adp_o, 'lr': learning_rate * 5},\n",
    "        {'params': model.tau_m_i, 'lr': learning_rate * 2.5},\n",
    "        {'params': model.tau_m_r, 'lr': learning_rate * 2.5},\n",
    "        {'params': model.tau_m_o, 'lr': learning_rate * 2.5}],\n",
    "        lr=learning_rate)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=.5)\n",
    "\n",
    "    # training network\n",
    "\n",
    "    # with sechdual\n",
    "    train_acc_list = train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        num_epochs=num_epochs,\n",
    "        fracInhibitory=frac)\n",
    "    test_acc = test(test_loader)\n",
    "    metaparameters['test_accuracies'][ind][1] = test_acc\n",
    "print(test_acc)\n",
    "\n",
    "test_acc = test(test_loader, 10)\n",
    "print(test_acc / 30 * 40.)\n",
    "\n",
    "test_acc = test(test_loader, 35)\n",
    "print(test_acc / 20. * 40.)\n",
    "\n",
    "test_acc, test_acc_classes = test_frame(test_loader)\n",
    "print(test_acc)\n",
    "print(test_acc_classes.shape)\n",
    "\n",
    "for i in range(11):\n",
    "    plt.plot(test_acc_classes[i], label=str(i))\n",
    "plt.legend()\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaparameters = {'test_accuracies': [[0.0, 0.7363231803797469],\n",
    "  [0.25, 0.769649920886076],\n",
    "  [0.5, 0.7460541930379747],\n",
    "  [0.75, 0.7729034810126583],\n",
    "  [1.0, 0.7579905063291139]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Fraction of Inhibitory Neurons=%{x}<br>Accuracy=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          0.25,
          0.5,
          0.75,
          1
         ],
         "xaxis": "x",
         "y": [
          0.7363231803797469,
          0.769649920886076,
          0.7460541930379747,
          0.7729034810126583,
          0.7579905063291139
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Fraction of Inhibitory Neurons"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import scipy as scp\n",
    "from scipy import stats\n",
    "x = [metaparameters['test_accuracies'][i][0] for i in range(5)]\n",
    "y = [metaparameters['test_accuracies'][i][1] for i in range(5)]\n",
    "df=pd.DataFrame({'Fraction of Inhibitory Neurons':x,'Accuracy':y})\n",
    "px.scatter(df,x='Fraction of Inhibitory Neurons',y='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "- Compare accuracy and weight distribution to original model (fraction)\n",
    "- Plot spike times for some neurons (maybe find some summary for all spike times)\n",
    "- Get more statistics for accuracies (varying epochs in a small window)\n",
    "- Investigate vanishing firing rate problem\n",
    "    - Firing rate, loss over epoch plot\n",
    "- Why do all negative neurons still produce acceptable output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
