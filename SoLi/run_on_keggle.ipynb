{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.autograd import Variable\nfrom torch.optim.lr_scheduler import StepLR\nimport matplotlib.pyplot as plt\nimport math\nimport matplotlib\nfrom torch.utils import data","metadata":{"execution":{"iopub.status.busy":"2021-12-04T23:57:23.142746Z","iopub.execute_input":"2021-12-04T23:57:23.143367Z","iopub.status.idle":"2021-12-04T23:57:24.698474Z","shell.execute_reply.started":"2021-12-04T23:57:23.143267Z","shell.execute_reply":"2021-12-04T23:57:24.697612Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"seq_length = 40\nbatch_size =32\ntrain_x = np.load('/kaggle/input/nddlsoli/train_x.npy')/255.\ntrain_y = np.load('/kaggle/input/nddlsoli/train_y.npy')\n# plt.hist(train_y)\n\nvalid_x = np.load('/kaggle/input/nddlsoli/valid_x.npy')/255.\nvalid_y = np.load('/kaggle/input/nddlsoli/valid_y.npy')\n\ntest_x = np.load('/kaggle/input/nddlsoli/test_x.npy')/255.\ntest_y = np.load('/kaggle/input/nddlsoli/test_y.npy')","metadata":{"execution":{"iopub.status.busy":"2021-12-04T23:57:51.944780Z","iopub.execute_input":"2021-12-04T23:57:51.945066Z","iopub.status.idle":"2021-12-04T23:58:04.333871Z","shell.execute_reply.started":"2021-12-04T23:57:51.945031Z","shell.execute_reply":"2021-12-04T23:58:04.333122Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# remove the background images\nidx_not_11 = np.where(test_y<11)[0]\ntest_x = test_x[idx_not_11,:,:,:]\ntest_y = test_y[idx_not_11]\n\n_,seq_length,dim_row,dim_col = train_x.shape\nprint('input dataset shap: ',train_x.shape)\nprint('output dataset shap: ',train_y.shape)\n\ndef get_DataLoader(train_x,train_y,batch_size=200,is_binary=False):\n    train_y = np.tile(train_y,seq_length).reshape(seq_length,len(train_y)).T\n    if is_binary:\n        train_dataset = data.TensorDataset(torch.Tensor((train_x>0)*1.), torch.Tensor(train_y))\n    else:\n        train_dataset = data.TensorDataset(torch.Tensor(train_x), torch.Tensor(train_y))\n    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    return train_loader\n\ntrain_loader = get_DataLoader(train_x,train_y,batch_size=batch_size)\ntest_loader = get_DataLoader(test_x,test_y,batch_size=batch_size)\nvalid_loader = get_DataLoader(valid_x,valid_y,batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T23:58:07.681722Z","iopub.execute_input":"2021-12-04T23:58:07.682104Z","iopub.status.idle":"2021-12-04T23:58:08.982361Z","shell.execute_reply.started":"2021-12-04T23:58:07.682068Z","shell.execute_reply":"2021-12-04T23:58:08.981569Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(40)\nthresh = 0.5  # neuronal threshold\nb_j0 = 0.1  # neural threshold baseline\nR_m = 1  # membrane resistance\nlens = 0.5\ngamma = 0.5","metadata":{"execution":{"iopub.status.busy":"2021-12-04T23:58:19.293340Z","iopub.execute_input":"2021-12-04T23:58:19.294099Z","iopub.status.idle":"2021-12-04T23:58:19.300832Z","shell.execute_reply.started":"2021-12-04T23:58:19.294053Z","shell.execute_reply":"2021-12-04T23:58:19.299921Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def gaussian(x, mu=0., sigma=.5):\n    return torch.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / torch.sqrt(2 * torch.tensor(math.pi)) / sigma\n\nclass ActFun_adp(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input):  # input = membrane potential- threshold\n        ctx.save_for_backward(input)\n        return input.gt(0).float()  # is firing ???\n\n    @staticmethod\n    def backward(ctx, grad_output):  # approximate the gradients\n        input, = ctx.saved_tensors\n        grad_input = grad_output.clone()\n        # temp = abs(input) < lens\n        scale = 6.0\n        hight = .15\n        # temp = torch.exp(-(input**2)/(2*lens**2))/torch.sqrt(2*torch.tensor(math.pi))/lens\n        temp = gaussian(input, mu=0., sigma=lens) * (1. + hight) \\\n               - gaussian(input, mu=lens, sigma=scale * lens) * hight \\\n               - gaussian(input, mu=-lens, sigma=scale * lens) * hight\n        return grad_input * temp.float() * gamma\n\n\nact_fun_adp = ActFun_adp.apply\n\n\ndef mem_update_adp(inputs, mem, spike, tau_adp, b, tau_m, dt=1, isAdapt=1):\n    isCuda = torch.cuda.is_available()\n    if isCuda:\n        alpha = torch.exp(-1. * dt / tau_m).cuda()\n        ro = torch.exp(-1. * dt / tau_adp).cuda()\n    else:\n        alpha = torch.exp(-1. * dt / tau_m)\n        ro = torch.exp(-1. * dt / tau_adp)\n    if isAdapt:\n        beta = 1.84\n    else:\n        beta = 0.\n\n    b = ro * b + (1 - ro) * spike\n    B = b_j0 + beta * b\n\n    mem = mem * alpha + (1 - alpha) * R_m * inputs - B * spike * dt\n    inputs_ = mem - B\n    spike = act_fun_adp(inputs_)  # act_fun : approximation firing function\n    return mem, spike, B, b\n\ndef output_Neuron(inputs, mem, tau_m, dt=1):\n    \"\"\"\n    The read out neuron is leaky integrator without spike\n    \"\"\"\n    alpha = torch.exp(-1. * dt / tau_m)\n    mem = mem *alpha +  (1-alpha)*inputs\n    return mem","metadata":{"execution":{"iopub.status.busy":"2021-12-04T23:58:29.937493Z","iopub.execute_input":"2021-12-04T23:58:29.938047Z","iopub.status.idle":"2021-12-04T23:58:29.954183Z","shell.execute_reply.started":"2021-12-04T23:58:29.938000Z","shell.execute_reply":"2021-12-04T23:58:29.953040Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class RNN_s(nn.Module):\n    def __init__(self, sub_seq_length,criterion):\n        super(RNN_s, self).__init__()\n        self.criterion = criterion\n        self.sub_seq_length = sub_seq_length\n        \n        self.n = 256\n        self.dense_i = nn.Linear(1024,self.n)\n        self.dense_i2r = nn.Linear(self.n,self.n)\n        self.dense_r = nn.Linear(self.n,self.n)\n        self.dense_o = nn.Linear(self.n,11)\n        \n        self.tau_adp_i = nn.Parameter(torch.Tensor(self.n))\n        self.tau_adp_r = nn.Parameter(torch.Tensor(self.n))\n        self.tau_adp_o = nn.Parameter(torch.Tensor(11))\n        \n        self.tau_m_i = nn.Parameter(torch.Tensor(self.n))\n        self.tau_m_r = nn.Parameter(torch.Tensor(self.n))\n        self.tau_m_o = nn.Parameter(torch.Tensor(11))\n        \n        nn.init.normal_(self.tau_adp_i,20,5)\n        nn.init.normal_(self.tau_adp_r,20,5)\n        nn.init.normal_(self.tau_adp_o,20,5)\n        \n        nn.init.normal_(self.tau_m_i,20,5)\n        nn.init.normal_(self.tau_m_r,20,5)\n        nn.init.normal_(self.tau_m_o,3,1)\n        \n\n        \n        self.b_h = self.b_o = b_j0\n\n    def forward(self, input,labels=None,sub_length =5,output_type='integrator'):\n        b,s,l = input.shape\n        if torch.cuda.is_available():\n            mem_layer1 = spike_layer1 = mem_layer2 = spike_layer2 = torch.rand(b, self.n).cuda()\n            mem_layer3 = spike_layer3 = mem_output = torch.rand(b, 11).cuda()\n            self.b_i = self.b_o=self.b_r = b_j0\n            output = torch.zeros(b, 11).cuda()\n        else:\n            mem_layer1 = spike_layer1 = mem_layer2 = spike_layer2 = torch.rand(b, self.n)\n            mem_layer3 = spike_layer3 = mem_output = torch.rand(b, 11)\n            self.b_i = self.b_o=self.b_r = b_j0\n            output = torch.zeros(b, 11)\n        loss = 0\n        predictions = []\n        fr = []\n        for i in range(s):\n            input_x=input[:,i,:]\n            d1_output = self.dense_i(input_x)\n            mem_layer1, spike_layer1, theta_i, self.b_i = mem_update_adp(d1_output, mem_layer1, spike_layer1, self.tau_adp_i, self.b_i,self.tau_m_i)\n            r_input = self.dense_i2r(spike_layer1)+self.dense_r(spike_layer2)\n            mem_layer2, spike_layer2, theta_r, self.b_r = mem_update_adp(r_input, mem_layer2, spike_layer2, self.tau_adp_r, self.b_r,self.tau_m_r)\n            o_input = self.dense_o(spike_layer2)\n            if output_type == 'adp-mem':\n                mem_layer3, spike_layer3, theta_o, self.b_o = mem_update_adp(o_input, mem_layer3, spike_layer3, self.tau_adp_o, self.b_o,self.tau_m_o)\n            elif output_type == 'integrator':\n                mem_layer3 = output_Neuron(o_input, mem_layer3, self.tau_m_o)\n            \n            output = F.log_softmax(mem_layer3,dim=-1)#\n            \n            # output_  = F.log_softmax(output,dim=1)\n            predictions.append(output.data.cpu().numpy())\n            if labels is not None:\n                loss += self.criterion(output, labels[:, i])\n            \n            fr.append((spike_layer1.detach().mean().cpu().numpy()+spike_layer2.detach().mean().cpu().numpy())/2.)\n\n        predictions = torch.tensor(predictions)\n        return predictions, loss,np.mean(fr)\n\n    def predict(self,input):\n        prediction, _= self.forward(input)\n        return prediction","metadata":{"execution":{"iopub.status.busy":"2021-12-04T23:58:36.770011Z","iopub.execute_input":"2021-12-04T23:58:36.770419Z","iopub.status.idle":"2021-12-04T23:58:36.792636Z","shell.execute_reply.started":"2021-12-04T23:58:36.770382Z","shell.execute_reply":"2021-12-04T23:58:36.791670Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def test(data_loader,after_num_frames=0):\n    test_acc = 0.\n    sum_samples = 0\n    fr_list = []\n    for i, (images, labels) in enumerate(data_loader):\n        images = images.view(-1, seq_length, 1024).to(device)\n        labels = labels.view((-1,seq_length)).long().to(device)\n        predictions, _,fr = model(images)\n        _, predicted = torch.max(predictions.data, 2)\n        labels = labels.cpu()\n        predicted = predicted.cpu().t()\n        fr_list.append(fr)\n        \n        test_acc += (predicted[:,after_num_frames:] == labels[:,after_num_frames:]).sum()\n        \n        sum_samples = sum_samples + predicted.numel()\n    print('Mean FR: ',np.mean(fr_list))\n    return test_acc.data.cpu().numpy() / sum_samples\n\ndef test_frame(data_loader,after_num_frames=0):\n    test_acc = 0.\n    sum_samples = 0\n    test_acc_classes = np.zeros((11,40))\n    test_acc_count = np.zeros((11,1))                                       \n    fr_list = []\n    for i, (images, labels) in enumerate(data_loader):\n        images = images.view(-1, seq_length, 1024).to(device)\n        labels = labels.view((-1,seq_length)).long().to(device)\n        predictions, _,fr = model(images)\n        _, predicted = torch.max(predictions.data, 2)\n        labels = labels.cpu()\n        predicted = predicted.cpu().t()\n        fr_list.append(fr)\n        \n        test_acc += (predicted[:,after_num_frames:] == labels[:,after_num_frames:]).float().mean(axis=0)\n        f_test = predicted[:,after_num_frames:] == labels[:,after_num_frames:]\n        for i in range(f_test.shape[0]):\n            tmp = labels[i,0]\n            test_acc_classes[tmp] += f_test[i].float().cpu().numpy()\n            test_acc_count[tmp] += 1\n        if i==1:\n            print(f_test.shape)\n        \n        sum_samples = sum_samples + predicted.numel()\n    print('Mean FR: ',np.mean(fr_list))\n\n    return test_acc.data.cpu().numpy() / i,test_acc_classes/test_acc_count","metadata":{"execution":{"iopub.status.busy":"2021-12-04T23:58:39.683108Z","iopub.execute_input":"2021-12-04T23:58:39.683624Z","iopub.status.idle":"2021-12-04T23:58:39.699543Z","shell.execute_reply.started":"2021-12-04T23:58:39.683586Z","shell.execute_reply":"2021-12-04T23:58:39.698056Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train(model,loader,optimizer,scheduler=None,num_epochs=10):\n    best_acc = 0\n    path = '/kaggel/working/'  # .pth'\n    acc_list=[]\n    for epoch in range(num_epochs):\n        train_acc = 0\n        train_loss_sum = 0\n        sum_samples = 0\n        fr_list = []\n        for i, (images, labels) in enumerate(loader):\n            images = images.view(-1, seq_length, 1024).requires_grad_().to(device)#images.view(-1, num_samples, input_dim).requires_grad_().to(device)\n            labels = labels.view((-1,seq_length)).long().to(device)\n            optimizer.zero_grad()\n            \n            predictions, train_loss,fr_ = model(images, labels)\n            _, predicted = torch.max(predictions.data, 2)\n            \n            train_loss.backward(retain_graph=True)\n            train_loss_sum += train_loss\n            fr_list.append(fr_)\n            optimizer.step()\n\n            labels = labels.cpu()\n            predicted = predicted.cpu().t()\n            train_acc += (predicted == labels).sum()\n            sum_samples = sum_samples + predicted.numel()\n    \n        if scheduler is not None:\n            scheduler.step()\n            \n        train_acc = train_acc.data.cpu().numpy() / sum_samples\n        valid_acc = test(valid_loader)\n        \n        if valid_acc>best_acc and train_acc>0.80:\n            best_acc = valid_acc\n            torch.save(model, path+str(best_acc)[:5]+'-frame-v3-inte.pth')\n\n        acc_list.append(train_acc)\n        print('epoch: {:3d}, Train Loss: {:.4f}, Train Acc: {:.4f},Valid Acc: {:.4f},fr: {:.4f}'.format(epoch,\n                                                                           train_loss_sum.item()/len(loader)/(seq_length),\n                                                                           train_acc,valid_acc,np.mean(fr_list)), flush=True)\n    return acc_list","metadata":{"execution":{"iopub.status.busy":"2021-12-05T00:28:51.933702Z","iopub.execute_input":"2021-12-05T00:28:51.933959Z","iopub.status.idle":"2021-12-05T00:28:51.946393Z","shell.execute_reply.started":"2021-12-05T00:28:51.933930Z","shell.execute_reply":"2021-12-05T00:28:51.944655Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"num_epochs = 35\nsub_seq_length = 10\ncriterion = nn.NLLLoss()#nn.CrossEntropyLoss()\nmodel = RNN_s(sub_seq_length=sub_seq_length,criterion=criterion)\n# model.load('./model/796-mem.pth')\n# model.load_state_dict(torch.load('./model/0.766-frame.pth'))\n# model = torch.load('./model/0.833-frame-v3-inte.pth')\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device:\",device)\nmodel.to(device)\n\nlearning_rate =1.5e-2#1e-2\n\nbase_params = [model.dense_i.weight, model.dense_i.bias, \n               model.dense_o.weight, model.dense_o.bias,\n               model.dense_r.weight, model.dense_r.bias, \n               model.dense_i2r.weight, model.dense_i2r.bias]\noptimizer = torch.optim.Adam([\n    {'params': base_params},\n    {'params': model.tau_adp_i, 'lr': learning_rate * 5},\n    {'params': model.tau_adp_r, 'lr': learning_rate * 5},\n    {'params': model.tau_adp_o, 'lr': learning_rate * 5},\n    {'params': model.tau_m_i, 'lr': learning_rate * 2.5},\n    {'params': model.tau_m_r, 'lr': learning_rate * 2.5},\n    {'params': model.tau_m_o, 'lr': learning_rate * 2.5}],\n    lr=learning_rate)\n\n\nscheduler = StepLR(optimizer, step_size=30, gamma=.5) \n\n# training network\n\n# with sechdual\ntrain_acc_list = train(model,train_loader,optimizer,scheduler,num_epochs=num_epochs)\ntest_acc = test(test_loader)\nprint(test_acc)\n\ntest_acc = test(test_loader,10)\nprint(test_acc/30*40.)\n\ntest_acc = test(test_loader,35)\nprint(test_acc/20.*40.)\n\ntest_acc,test_acc_classes = test_frame(test_loader)\nprint(test_acc)\nprint(test_acc_classes.shape)\n\nfor i in range(11):\n    plt.plot(test_acc_classes[i],label=str(i))\nplt.legend()\nplt.xlabel('Frame')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T00:28:57.115778Z","iopub.execute_input":"2021-12-05T00:28:57.116059Z","iopub.status.idle":"2021-12-05T00:41:19.941012Z","shell.execute_reply.started":"2021-12-05T00:28:57.116027Z","shell.execute_reply":"2021-12-05T00:41:19.940314Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}